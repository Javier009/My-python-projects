{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c398522-febc-492d-8e27-75fa6353eb3b",
   "metadata": {},
   "source": [
    "# Competitive analysis with SimilarWeb API\n",
    "Notes:\n",
    "1) Top websites pero country are from the last momnthe avilable and seems that is not allowed to have them for aggregated time frames\n",
    "2) Relevant sections of the API for this project: Top domains  per country, Total visits, Avg. session duration in Mobile and desktop (two different sections)\n",
    "3) Data granularity: Country-->Monthly.\n",
    "4) Data collected: For 50 countries, 6 selected websites, top 10 other websites (exlude adult websites): total visits, average session duration\n",
    "\n",
    "Data considerations:\n",
    "Data structures hits:\n",
    "    1) Granularity: Monthly, 49 countries since China is not avilable in SimilarWeb and also not very relevant for Google Busines\n",
    "    2) Timeframe: 2019-09 to 2022-09 --> 36 months \n",
    "    3) Top 10 + 8 websites of specified cohort for 49 countries = 49 hits\n",
    "    4) Total visits 18 websites * 50 countries = 882 hits\n",
    "    5) Desktop Average session duration * 50 countries = 882 hits\n",
    "    6) Mobile Average session duration * 50 countries = 882 hits\n",
    "    7) Total hits = 2695\n",
    "    8) Hits for testing = 300\n",
    "\n",
    "## Data structures final tables shapes to be stored in csv files :\n",
    "\n",
    "    1) Granularity: Monthly, 49 countries since China is not avilable in SimilarWeb and also not very relevant for Google Busines\n",
    "    2) Timeframe: 2019-09 to 2022-09 --> 36 months \n",
    "    3) Total visits 17 websites * 50 * 36 months = 31752 rows\n",
    "    4) Average session duration 17 websites * 50 * 36 months = 29988 rows * 2 (Desktop and Mobile) =  63505 rows\n",
    "\n",
    "Process:\n",
    "Countries considereed:\n",
    " 1) From Google Ecosystem analysis extract top 50 countries, store them in a CSV file and upload it file to this notebook\n",
    " 2) Import SimilarWeb countries provided by the team in a CSV file\n",
    " 2.1) Modify Google top countries to match SimilarWeb string pattern to be modify at end stage\n",
    " 3) Verify that Google top 50 countries are avilable in SimilarWeb countries\n",
    "Websites considered:\n",
    " 1) Build a data structure (list, tuple whatever) with Websites present in each country no matter the ranking posisiton:\n",
    "\n",
    "     reddit.com\n",
    "     tiktok.com\n",
    "     instagram.com\n",
    "     facebook.com\n",
    "     amazon.com\n",
    "     youtube.com\n",
    "\n",
    " 2) Exlude Adult website from the analysis:\n",
    "     Build a list of XXX websites in the world to be exluded using Simi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd418b2-9852-4bf4-8588-2768d377f452",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Libraries imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4cdc014-1df1-46e1-acba-68686b200a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9d6de9-7e65-4756-ac21-523d5f2fd07d",
   "metadata": {},
   "source": [
    "## Import Google countries to be reviewed in the SimilarWeb Api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe22d6-8bcd-4b15-9528-7cf9313dbe75",
   "metadata": {
    "tags": []
   },
   "source": [
    "## API hits to extract top 10K adult websites worldwide that will be excluded from the analyses \n",
    "### IMPORTANT: RUN every time that you need to do a full refresh of the data, otherwise extract topwebsites from the CVS file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7e4778-a046-45e7-a22b-de0e0cd438fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Run this section once since data is stored in a excel file. Unless the month ended and we have 3000 hits again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce6613-5bd9-4e08-87b5-3520cceb93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adult web sites to be exluded ## TESTING to see if both geos criteria show same data BEFORE RUNNING API FOR TOP 100 PAGES\n",
    "\n",
    "access_key = 'contact owner'\n",
    "all_geos = ('world', 'worldwide')\n",
    "\n",
    "adult_websites_api_path_one = f'https://api.similarweb.com/v1/website/$Adult/topsites/total?api_key={access_key}&start_date=2022-09&end_date=2022-09&country={all_geos[0]}&format=json&page=1'\n",
    "adult_websites_api_path_two = f'https://api.similarweb.com/v1/website/$Adult/topsites/total?api_key={access_key}&start_date=2022-09&end_date=2022-09&country={all_geos[1]}&format=json&page=1'\n",
    "\n",
    "adult_websites_api_path_option_one = requests.get(adult_websites_api_path_one).json()\n",
    "adult_websites_api_path_option_two = requests.get(adult_websites_api_path_two).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791166b-8baa-49a2-b291-7da9a4b59deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_geos = ('world', 'worldwide')\n",
    "adult_websites_api_path_two = f'https://api.similarweb.com/v1/website/$Adult/topsites/total?api_key={access_key}&start_date=2022-09&end_date=2022-09&country={all_geos[1]}&format=json&page=1'\n",
    "adult_websites_api_path_option_two = requests.get(adult_websites_api_path_two).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936815e-6a77-4245-8100-5b55112b3180",
   "metadata": {},
   "outputs": [],
   "source": [
    "inconcistencies = []\n",
    "\n",
    "if 'No data for requested country' in adult_websites_api_path_option_two['meta']['error_message']:\n",
    "    print('OK! No data in option 2!')\n",
    "else:\n",
    "    for web_site_dict in  adult_websites_api_path_option_one['top_sites']:\n",
    "        rank = web_site_dict['rank']\n",
    "        domain_option_one = web_site_dict['domain']\n",
    "\n",
    "        domain_option_two = [ w for w in [i for i in adult_websites_api_path_option_two['top_sites'] ] if w['rank'] == rank ][0]['domain']\n",
    "\n",
    "        if domain_option_one == domain_option_two:\n",
    "            pass\n",
    "        else:\n",
    "            inconcistencies.append((1 (domain_option_one, domain_option_two) )) \n",
    "\n",
    "    if len(inconcistencies) == 0:\n",
    "        print('OK! Both sources are the same use option 1 or 2')\n",
    "    else:\n",
    "        print(f'Total inconcistencies = {sum([i[0] for i in inconcistencies])}')\n",
    "        for inc in inconcistencies:\n",
    "            print(inc[1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ea113-e7f1-405b-9947-d70c6091dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_websites_api_path_option_two['meta']['error_message']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661744b5-dd43-4895-b979-325966859e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output from option 2 for double check, error_message should be recived\n",
    "\n",
    "adult_websites_api_path_option_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cdd0b2-48f1-43dd-8ae7-bcf14a352ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look if there is data in page 100 to see if it returns data\n",
    "access_key = 'contact owner'\n",
    "all_geos = ('world', 'worldwide')\n",
    "\n",
    "adult_websites_api_path_page_100_test = f'https://api.similarweb.com/v1/website/$Adult/topsites/total?api_key={access_key}&start_date=2022-09&end_date=2022-09&country={all_geos[0]}&format=json&page=100'\n",
    "adult_websites_api_path_page_100_test = requests.get(adult_websites_api_path_page_100_test).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9aa0c4-9d9f-4a9b-91f2-89f45a6edcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_websites_api_path_page_100_test['top_sites'][0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45c01f-0e38-4fd3-8e9c-c792dd80a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY ONCE sice data will live in a csv file! \n",
    "\n",
    "# Run a loop to get all domains in 100 pages to exlude 10K top xxx websites in the world:  \n",
    "access_key = 'contact owner'\n",
    "all_geos = ('world', 'worldwide')\n",
    "\n",
    "p_ranks =  []\n",
    "p_domains = []\n",
    "\n",
    "for page in range(1,100+1):\n",
    "    adult_websites_api_path = f'https://api.similarweb.com/v1/website/$Adult/topsites/total?api_key={access_key}&start_date=2022-09&end_date=2022-09&country={all_geos[0]}&format=json&page={page}'\n",
    "    adult_websites_api_data = requests.get(adult_websites_api_path).json()\n",
    "    \n",
    "    for web_site_dict in  adult_websites_api_data['top_sites']:\n",
    "        \n",
    "        rank = web_site_dict['rank']\n",
    "        domain = web_site_dict['domain']\n",
    "        \n",
    "        p_ranks.append(rank)\n",
    "        p_domains.append(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dfed2c-9d26-48e3-a1f2-f060cf26ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(p_ranks), len(p_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844b9eb-f9ea-4ba5-aabd-c1f74b4dd35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Adults websites data frame\n",
    "#RUN ONLY ONCE SINCE DATA WILL BE STORED IN A CSV FILE AND AVED IN PLX TABLE\n",
    "\n",
    "adults_web_sites = pd.DataFrame({'Rank': p_ranks,\n",
    "                                 'Domain': p_domains})\n",
    "adults_web_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f56d42-4959-467f-afca-69e349b6b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the data frame in a csv file that will be exported as plx table\n",
    "#Use this data frame and not hit the API again until next month that we have 3000 hits again \n",
    "adults_web_sites.to_excel('Desktop/adult_websites.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9255068-769e-47bf-97af-e31f0c245644",
   "metadata": {},
   "source": [
    "## Load adult websites from Excel file. This websites will be exluded form anlaysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "442c516c-ba9b-4925-81d1-f6bee758d2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>xvideos.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>pornhub.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>xnxx.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>xhamster.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>realsrv.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>moro-douga.link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>umechan.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>pimp61.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>baiselibre.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>sextingbook.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rank           Domain\n",
       "0         1      xvideos.com\n",
       "1         2      pornhub.com\n",
       "2         3         xnxx.com\n",
       "3         4     xhamster.com\n",
       "4         5      realsrv.com\n",
       "...     ...              ...\n",
       "9995   9996  moro-douga.link\n",
       "9996   9997      umechan.net\n",
       "9997   9998       pimp61.net\n",
       "9998   9999   baiselibre.com\n",
       "9999  10000  sextingbook.com\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adults_web_sites = pd.read_excel('adultwebsites_to_exlude.xlsx')\n",
    "adults_web_sites "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3405f9aa-5a53-435a-a6e7-6017f473025c",
   "metadata": {},
   "source": [
    "## Run API hits for data collection\n",
    "### Google countries mapped with SimilarWeb codes file upload and constant websites list definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba531d35-7056-45fe-ab27-92fb5871c5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  country_code_google country_code_SW country_code_lower_SW  \\\n",
       " 0                  US              US                    us   \n",
       " 1                  GB              GB                    gb   \n",
       " 2                  DE              DE                    de   \n",
       " 3                  JP              JP                    jp   \n",
       " 4                  NL              NL                    nl   \n",
       " \n",
       "    Search revenue rank  \n",
       " 0                    1  \n",
       " 1                    2  \n",
       " 2                    3  \n",
       " 3                    4  \n",
       " 4                    5  ,\n",
       " (49, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_data_frame = pd.read_excel('similarweb_countries.xlsx')\n",
    "#Exlude China\n",
    "countries_data_frame = countries_data_frame[countries_data_frame['country_code_lower_SW'] != 'Not in SW']\n",
    "#Rank countries (They come sorted)\n",
    "countries_data_frame['Search revenue rank'] = [i for i in range(1,50)]\n",
    "countries_data_frame.head(), countries_data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "295f3499-bc46-41a8-b388-b34dbc08b105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['us',\n",
       " 'gb',\n",
       " 'de',\n",
       " 'jp',\n",
       " 'nl',\n",
       " 'fr',\n",
       " 'ca',\n",
       " 'au',\n",
       " 'il',\n",
       " 'es',\n",
       " 'br',\n",
       " 'it',\n",
       " 'in',\n",
       " 'se',\n",
       " 'pl',\n",
       " 'mx',\n",
       " 'vn',\n",
       " 'kr']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define how many countries we want to get data from the SW API\n",
    "top_countries_to_get = 15\n",
    "## Conutries that are not in the top 15 but we would like to have them\n",
    "aditional_countries = ['mx', 'vn', 'kr']\n",
    "final_countries_to_get = list(countries_data_frame[countries_data_frame['Search revenue rank'] <= top_countries_to_get]['country_code_lower_SW']) + aditional_countries\n",
    "final_countries_to_get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc84fde-ed51-460e-aaff-ca208f464a5f",
   "metadata": {},
   "source": [
    "### Specify which domains you want to be present in all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd40fc50-9f8b-4039-985e-f6ea496dcbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazon.com',\n",
       " 'target.com',\n",
       " 'walmart.com',\n",
       " 'ebay.com',\n",
       " 'shopify.com',\n",
       " 'etsy.com',\n",
       " 'craigslist.com',\n",
       " 'nike.com',\n",
       " 'bestbuy.com',\n",
       " 'apple.com',\n",
       " 'samsung.com',\n",
       " 'homedepot.com']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#constant Webstie to be included  across countries\n",
    "#constant_web_sites =  ['google.com','youtube.com','facebook.com','amazon.com', 'twitter.com', 'instagram.com', 'reddit.com','tiktok.com']\n",
    "\n",
    "constant_web_sites = ['amazon.com',\n",
    "                      'target.com',\n",
    "                      'walmart.com',\n",
    "                      'ebay.com',\n",
    "                      'shopify.com',\n",
    "                      'etsy.com',\n",
    "                      'craigslist.com',\n",
    "                      'nike.com' ,\n",
    "                      'bestbuy.com',\n",
    "                      'apple.com',\n",
    "                      'samsung.com',\n",
    "                      'homedepot.com']\n",
    "\n",
    "constant_web_sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5670d3-a899-4f67-b215-8d40e7b166ea",
   "metadata": {},
   "source": [
    "## Define analyis parameters for selected cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "921a0f80-99fc-483e-a72d-43c3ec8f205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define if the analysis will focus only one a specific set of countries or in all selected markets  ## --> For all countries: countries_of_focus = [] \n",
    "\n",
    "countries_of_focus = ['us']  \n",
    "\n",
    "if len(countries_of_focus)>0:\n",
    "    final_countries_to_get = countries_of_focus\n",
    "else:\n",
    "    final_countries_to_get = final_countries_to_get\n",
    "\n",
    "    \n",
    "## DEFINE THE TYPE OF ANALYSIS TO BE DONE: Selected properties only OR include all top x websites defined in the variable threshold_top_domains\n",
    "### False for all top x websites, True for selected cohort\n",
    "\n",
    "selected_domains_cohort_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35e4e8b6-b764-403a-8f31-1a9fb40dfc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['us'],\n",
       " True,\n",
       " ['amazon.com',\n",
       "  'target.com',\n",
       "  'walmart.com',\n",
       "  'ebay.com',\n",
       "  'shopify.com',\n",
       "  'etsy.com',\n",
       "  'craigslist.com',\n",
       "  'nike.com',\n",
       "  'bestbuy.com',\n",
       "  'apple.com',\n",
       "  'samsung.com',\n",
       "  'homedepot.com'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_countries_to_get, selected_domains_cohort_only, constant_web_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f900c3c-5eeb-48bf-b3ac-ffd478a03491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of domains per top country present in final_countries_to_get\n",
    "threshold_top_domains = 40\n",
    "\n",
    "#Variables definition for API data pulls\n",
    "\n",
    "access_key = '9095e89d0b5649b0a1a7d2bb9c2c5816'\n",
    "granularity = 'daily'\n",
    "t0_date = '2019-10'\n",
    "t1_date = '2022-10'\n",
    "\n",
    "#Adults websites to exlude from analysis\n",
    "adult_domains_to_exlude = [adult_domain for adult_domain in adults_web_sites['Domain']]\n",
    "\n",
    "#LISTS WHICH WILL POPULATE DATA FAMES:\n",
    "\n",
    "## Desktop visits\n",
    "desktop_visits_dates = []\n",
    "desktop_visits_countries = []\n",
    "desktop_visits_domains = []\n",
    "desktop_visits_visits = [] \n",
    "\n",
    "\n",
    "## Mobile visits\n",
    "mobile_visits_dates = []\n",
    "mobile_visits_countries = []\n",
    "mobile_visits_domains = []\n",
    "mobile_visits_visits = [] \n",
    "\n",
    "\n",
    "## Desktop average session duration\n",
    "\n",
    "desktop_visit_dur_dates = []\n",
    "desktop_visit_dur_countries = []\n",
    "desktop_visit_dur_domains = []\n",
    "desktop_visit_dur_duration = [] \n",
    "\n",
    "\n",
    "## Mobile average session duration\n",
    "\n",
    "mobile_visit_dur_dates = []\n",
    "mobile_visit_dur_countries = []\n",
    "mobile_visit_dur_domains = []\n",
    "mobile_visit_dur_duration = [] \n",
    "\n",
    "\n",
    "for country_code in final_countries_to_get:\n",
    "    \n",
    "    if selected_domains_cohort_only == False:\n",
    "    \n",
    "         #1) Get top domains data from the API for iterating country\n",
    "\n",
    "        top_domains_path = f'https://api.similarweb.com/v1/website/$All/topsites/total?api_key={access_key}&start_date=2022-10&end_date=2022-10&country={country_code}&format=json&page=1'\n",
    "        top_websites_data = requests.get(top_domains_path).json()\n",
    "        top_websites_data_dicts = top_websites_data['top_sites']\n",
    "\n",
    "        ## Extract domains and ranks and domains exlusion step\n",
    "\n",
    "        country_domains_to_analyse = []\n",
    "\n",
    "        for dic in top_websites_data_dicts:\n",
    "            rank =  dic['rank']\n",
    "            domain = dic['domain']\n",
    "            country_domains_to_analyse.append([rank, domain])\n",
    "\n",
    "            #exlude adult websites and constant websites from top websites cohort --> Constant WebSites will be added in later stage of this algorithm\n",
    "            country_domains_to_analyse = [d for d in country_domains_to_analyse if d[1] not in adult_domains_to_exlude]\n",
    "            country_domains_to_analyse = [d for d in country_domains_to_analyse if d[1] not in constant_web_sites]\n",
    "\n",
    "\n",
    "        #3) Re rank websties avilable once adult and constant domains have been exluded        \n",
    "        for n in range(0,len(country_domains_to_analyse)):\n",
    "            country_domains_to_analyse[n].append(n)\n",
    "\n",
    "        #Capture domain and new rank: Based on the new rank, grab only top x = threshold_top_domains domains\n",
    "        country_domains_to_analyse = [d[1] for d in country_domains_to_analyse if d[2] <= threshold_top_domains]\n",
    "\n",
    "        #4)Add constant websites across countries to the list to be analysed\n",
    "\n",
    "        for constant_domain in constant_web_sites:\n",
    "                country_domains_to_analyse.append(constant_domain)\n",
    "\n",
    "        # Create a list from a set just to be sure that we are not duplicating domains\n",
    "\n",
    "        country_domains_to_analyse = list(set(country_domains_to_analyse))\n",
    "        \n",
    "    else:\n",
    "        country_domains_to_analyse = constant_web_sites\n",
    "                         \n",
    "    #5) Extract Visits data for each website\n",
    "\n",
    "    for domain in country_domains_to_analyse:\n",
    "\n",
    "        # API DESKTOP visits calls       \n",
    "        desktop_visits_path = f'https://api.similarweb.com/v1/website/{domain}/traffic-and-engagement/visits?api_key={access_key}&start_date={t0_date}&end_date={t1_date}&country={country_code}&granularity={granularity}&main_domain_only=false&format=json'\n",
    "        desktop_visits_data = requests.get(desktop_visits_path).json()     \n",
    "        desktop_visits_data_dicts = desktop_visits_data['visits'] \n",
    "\n",
    "\n",
    "        for date_visit in desktop_visits_data_dicts:\n",
    "            date = date_visit['date']\n",
    "            desktop_visits = int(date_visit['visits'])\n",
    "\n",
    "            #Populating visits lists that will build total traffic data frame\n",
    "\n",
    "            desktop_visits_dates.append(date)\n",
    "            desktop_visits_countries.append(country_code)\n",
    "            desktop_visits_domains.append(domain)\n",
    "            desktop_visits_visits.append(desktop_visits)\n",
    "            \n",
    "        # API MOBILE visits calls       \n",
    "        mobile_visits_path = f'https://api.similarweb.com/v2/website/{domain}/mobile-web/visits?api_key={access_key}&start_date={t0_date}&end_date={t1_date}&country={country_code}&granularity={granularity}&main_domain_only=false&format=json'\n",
    "        mobile_visits_data = requests.get(mobile_visits_path).json()     \n",
    "        mobile_visits_data_dicts = mobile_visits_data['visits'] \n",
    "\n",
    "        #Extract data from json structure to populate lists that will build total visits data frame\n",
    "\n",
    "        for date_visit in mobile_visits_data_dicts:\n",
    "            date = date_visit['date']\n",
    "            mobile_visits = int(date_visit['visits'])\n",
    "\n",
    "            #Populating visits lists that will build total traffic data frame\n",
    "\n",
    "            mobile_visits_dates.append(date)\n",
    "            mobile_visits_countries.append(country_code)\n",
    "            mobile_visits_domains.append(domain)\n",
    "            mobile_visits_visits.append(mobile_visits)\n",
    "            \n",
    "    #6) Extract average visit duration for Desktop\n",
    "\n",
    "        #Desktop average visit duration API call\n",
    "        desktop_average_visit_duration_path = f'https://api.similarweb.com/v1/website/{domain}/traffic-and-engagement/average-visit-duration?api_key={access_key}&start_date={t0_date}&end_date={t1_date}&country={country_code}&granularity={granularity}&main_domain_only=false&format=json&show_verified=false'\n",
    "        desktop_average_visit_duration_data = requests.get(desktop_average_visit_duration_path).json()\n",
    "        desktop_average_visit_duration_data_dicts = desktop_average_visit_duration_data['average_visit_duration']\n",
    "\n",
    "        #Extract data from json structure to populate lists that will build total visits data frame\n",
    "\n",
    "        for date_desk_session in desktop_average_visit_duration_data_dicts:\n",
    "            date = date_desk_session['date']\n",
    "            desk_average_visit_duration = date_desk_session['average_visit_duration']\n",
    "\n",
    "            #Populating visits lists that will build total traffic data frame\n",
    "\n",
    "            desktop_visit_dur_dates.append(date)\n",
    "            desktop_visit_dur_countries.append(country_code)\n",
    "            desktop_visit_dur_domains.append(domain)\n",
    "            desktop_visit_dur_duration.append(desk_average_visit_duration)\n",
    "\n",
    "\n",
    "    #7)Extract average visit duration for Mobile\n",
    "\n",
    "         #Mobile average visit duration API call\n",
    "        mobile_average_visit_duration_path = f'https://api.similarweb.com/v2/website/{domain}/mobile-web/average-visit-duration?api_key={access_key}&start_date={t0_date}&end_date={t1_date}&country={country_code}&granularity={granularity}&main_domain_only=false&format=json'\n",
    "        mobile_average_visit_duration_data = requests.get(mobile_average_visit_duration_path).json()\n",
    "        mobile_average_visit_duration_data_dicts = mobile_average_visit_duration_data['average_visit_duration']\n",
    "\n",
    "        for date_mobile_session in mobile_average_visit_duration_data_dicts:\n",
    "            date = date_mobile_session['date']\n",
    "            mobile_average_visit_duration = date_mobile_session['average_visit_duration']\n",
    "\n",
    "            #Populating visits lists that will build total traffic data frame\n",
    "\n",
    "            mobile_visit_dur_dates.append(date)\n",
    "            mobile_visit_dur_countries.append(country_code)\n",
    "            mobile_visit_dur_domains.append(domain)\n",
    "            mobile_visit_dur_duration.append(mobile_average_visit_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c4f3bb2-6f01-4078-acd6-560a5cb475bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13524, 13524, 13524, 13524)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## desktop visits\n",
    "len(desktop_visits_dates), len(desktop_visits_countries), len(desktop_visits_domains ), len(desktop_visits_visits )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64ed77b1-14d3-449f-a3c6-299cf4fa2e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13524, 13524, 13524, 13524)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Mobile visits\n",
    "len(mobile_visits_dates), len(mobile_visits_countries), len(mobile_visits_domains ), len(mobile_visits_visits )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2da0697-6920-4b00-ae35-baf3293f9503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13524, 13524, 13524, 13524)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Desktop average session duration\n",
    "len(desktop_visit_dur_dates ), len(desktop_visit_dur_countries ), len(desktop_visit_dur_domains ), len(desktop_visit_dur_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "062d1ef8-acf5-4238-b69f-d26aa323b82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13524, 13524, 13524, 13524)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Mobile average session duration\n",
    "\n",
    "len(mobile_visit_dur_dates), len(mobile_visit_dur_countries), len(mobile_visit_dur_domains), len(mobile_visit_dur_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b280eda6-2057-4a69-9a6c-6ac7f086642c",
   "metadata": {},
   "source": [
    "## Data Frames creation and export to Excel/CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b8601fa-0792-409d-99c9-8b88f355042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desktop visits data frame\n",
    "\n",
    "desktop_total_visits_df = pd.DataFrame({'Date':desktop_visits_dates,\n",
    "                                        'Country Code': desktop_visits_countries,\n",
    "                                        'Domain': desktop_visits_domains,\n",
    "                                        'Visits':desktop_visits_visits })\n",
    "\n",
    "desktop_total_visits_df['form_factor'] = 'Desktop Browser'\n",
    "\n",
    "\n",
    "#Mobile visits data frame\n",
    "\n",
    "\n",
    "mobile_total_visits_df = pd.DataFrame({'Date':mobile_visits_dates,\n",
    "                                       'Country Code': mobile_visits_countries,\n",
    "                                       'Domain': mobile_visits_domains,\n",
    "                                       'Visits':mobile_visits_visits })\n",
    "\n",
    "mobile_total_visits_df['form_factor'] = 'Mobile Browser'\n",
    "\n",
    "\n",
    "total_visits_df = pd.concat([desktop_total_visits_df,mobile_total_visits_df])\n",
    "\n",
    "\n",
    "#Avg Session Duration Desktop\n",
    "\n",
    "desktop_avg_visit_duration_df = pd.DataFrame({'Date':desktop_visit_dur_dates,\n",
    "                                              'Country Code': desktop_visit_dur_countries,\n",
    "                                              'Domain': desktop_visit_dur_domains,\n",
    "                                              'Avg. visit duration (sec)':desktop_visit_dur_duration })\n",
    "\n",
    "desktop_avg_visit_duration_df['form_factor'] = 'Desktop Browser'\n",
    "\n",
    "\n",
    "\n",
    "## Mobile average session duration\n",
    "\n",
    "\n",
    "mobile_avg_visit_duration_df = pd.DataFrame({'Date':mobile_visit_dur_dates,\n",
    "                                              'Country Code': mobile_visit_dur_countries,\n",
    "                                              'Domain': mobile_visit_dur_domains,\n",
    "                                              'Avg. visit duration (sec)':mobile_visit_dur_duration })\n",
    "\n",
    "\n",
    "mobile_avg_visit_duration_df['form_factor'] = 'Mobile Browser'\n",
    "\n",
    "\n",
    "avg_visit_duration_df = pd.concat([desktop_avg_visit_duration_df,mobile_avg_visit_duration_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d98dcb37-f817-4cc6-a133-b108b0294ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Visits</th>\n",
       "      <th>form_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>us</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>34352035</td>\n",
       "      <td>Desktop Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>us</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>33755586</td>\n",
       "      <td>Desktop Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>us</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>33222341</td>\n",
       "      <td>Desktop Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>us</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>31499011</td>\n",
       "      <td>Desktop Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-05</td>\n",
       "      <td>us</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>29918052</td>\n",
       "      <td>Desktop Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13519</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>us</td>\n",
       "      <td>homedepot.com</td>\n",
       "      <td>3214330</td>\n",
       "      <td>Mobile Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13520</th>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>us</td>\n",
       "      <td>homedepot.com</td>\n",
       "      <td>3073335</td>\n",
       "      <td>Mobile Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13521</th>\n",
       "      <td>2022-10-29</td>\n",
       "      <td>us</td>\n",
       "      <td>homedepot.com</td>\n",
       "      <td>3357813</td>\n",
       "      <td>Mobile Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13522</th>\n",
       "      <td>2022-10-30</td>\n",
       "      <td>us</td>\n",
       "      <td>homedepot.com</td>\n",
       "      <td>3243614</td>\n",
       "      <td>Mobile Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13523</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>us</td>\n",
       "      <td>homedepot.com</td>\n",
       "      <td>3013432</td>\n",
       "      <td>Mobile Browser</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27048 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Country Code         Domain    Visits      form_factor\n",
       "0      2019-10-01           us     amazon.com  34352035  Desktop Browser\n",
       "1      2019-10-02           us     amazon.com  33755586  Desktop Browser\n",
       "2      2019-10-03           us     amazon.com  33222341  Desktop Browser\n",
       "3      2019-10-04           us     amazon.com  31499011  Desktop Browser\n",
       "4      2019-10-05           us     amazon.com  29918052  Desktop Browser\n",
       "...           ...          ...            ...       ...              ...\n",
       "13519  2022-10-27           us  homedepot.com   3214330   Mobile Browser\n",
       "13520  2022-10-28           us  homedepot.com   3073335   Mobile Browser\n",
       "13521  2022-10-29           us  homedepot.com   3357813   Mobile Browser\n",
       "13522  2022-10-30           us  homedepot.com   3243614   Mobile Browser\n",
       "13523  2022-10-31           us  homedepot.com   3013432   Mobile Browser\n",
       "\n",
       "[27048 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_visits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e5c1a1c-ce10-404a-9b4f-ef941e3a54c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Avg. visit duration (sec)</th>\n",
       "      <th>form_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>us</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>560.486597</td>\n",
       "      <td>Desktop Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>us</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>558.516400</td>\n",
       "      <td>Desktop Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>us</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>560.577997</td>\n",
       "      <td>Desktop Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>us</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>554.735785</td>\n",
       "      <td>Desktop Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-05</td>\n",
       "      <td>us</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>584.717791</td>\n",
       "      <td>Desktop Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13519</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>us</td>\n",
       "      <td>homedepot.com</td>\n",
       "      <td>214.818836</td>\n",
       "      <td>Mobile Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13520</th>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>us</td>\n",
       "      <td>homedepot.com</td>\n",
       "      <td>246.660318</td>\n",
       "      <td>Mobile Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13521</th>\n",
       "      <td>2022-10-29</td>\n",
       "      <td>us</td>\n",
       "      <td>homedepot.com</td>\n",
       "      <td>249.046572</td>\n",
       "      <td>Mobile Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13522</th>\n",
       "      <td>2022-10-30</td>\n",
       "      <td>us</td>\n",
       "      <td>homedepot.com</td>\n",
       "      <td>246.376508</td>\n",
       "      <td>Mobile Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13523</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>us</td>\n",
       "      <td>homedepot.com</td>\n",
       "      <td>212.339184</td>\n",
       "      <td>Mobile Browser</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27048 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Country Code         Domain  Avg. visit duration (sec)  \\\n",
       "0      2019-10-01           us     amazon.com                 560.486597   \n",
       "1      2019-10-02           us     amazon.com                 558.516400   \n",
       "2      2019-10-03           us     amazon.com                 560.577997   \n",
       "3      2019-10-04           us     amazon.com                 554.735785   \n",
       "4      2019-10-05           us     amazon.com                 584.717791   \n",
       "...           ...          ...            ...                        ...   \n",
       "13519  2022-10-27           us  homedepot.com                 214.818836   \n",
       "13520  2022-10-28           us  homedepot.com                 246.660318   \n",
       "13521  2022-10-29           us  homedepot.com                 249.046572   \n",
       "13522  2022-10-30           us  homedepot.com                 246.376508   \n",
       "13523  2022-10-31           us  homedepot.com                 212.339184   \n",
       "\n",
       "           form_factor  \n",
       "0      Desktop Browser  \n",
       "1      Desktop Browser  \n",
       "2      Desktop Browser  \n",
       "3      Desktop Browser  \n",
       "4      Desktop Browser  \n",
       "...                ...  \n",
       "13519   Mobile Browser  \n",
       "13520   Mobile Browser  \n",
       "13521   Mobile Browser  \n",
       "13522   Mobile Browser  \n",
       "13523   Mobile Browser  \n",
       "\n",
       "[27048 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_visit_duration_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cbb189-560f-42e6-b18b-7ef89723b4a6",
   "metadata": {},
   "source": [
    "## Saving data in xlsx files to be uploaded to plx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "327d2fb2-f03e-4053-8dd0-2a8daf1c8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving data in excel/csv files\n",
    "#Saving the data frame in a csv file that will be exported as plx table\n",
    "#Use this data frame and not hit the API again until next month that we have 3000 hits again \n",
    "\n",
    "visits_file_name = 'sw_total_visits_traffic_black_firday.xlsx'\n",
    "session_duration_file_name = 'sw_avg_visit_duation_black_friday.xlsx'\n",
    "\n",
    "total_visits_df.to_excel(f'Documents/{visits_file_name}')\n",
    "avg_visit_duration_df.to_excel(f'Documents/{session_duration_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bff84e1-d9dc-4cbd-ba50-61cdec598d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f4d1f-45d0-4354-8db9-7f32b7f45d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc7000-a162-465b-8286-e63723bc40a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0954c0b-b450-4967-bd05-e944ebcc0632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
